{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import seaborn as sb\n",
    "from sklearn.datasets import make_moons \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from beeprint import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= make_moons(n_samples= 5 , noise= 0.2 , random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,) (5,) (5, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(a[0])\n",
    "y = np.array(a[1])\n",
    "x_ = x[:,0]\n",
    "print(x_.shape , y.shape , x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x[:,1]\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = sb.scatterplot(x = x_ , y = x1 , hue = x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.9\n",
    "xrownumber = x.shape[0]\n",
    "yrownumber = y.shape[0]\n",
    "xdatum = int(split * xrownumber)\n",
    "ydatum = int(split * yrownumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x[0:xdatum , :]\n",
    "x_test = x[xdatum: , :]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y[0:ydatum]\n",
    "y_test = y[ydatum:, ]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnet = [\n",
    "    {\"input_layer\" : 2 , \"output_layer\" : 5 , \"activation\" : \"relu\"} ,\n",
    " #   {\"input_layer\" : 25 , \"output_layer\" : 50 , \"activation\" : \"relu\"} ,\n",
    " #   {\"input_layer\" : 50 , \"output_layer\" : 50 , \"activation\" : \"relu\"} ,\n",
    " #   {\"input_layer\" : 50 , \"output_layer\" : 25 , \"activation\" : \"relu\"} ,\n",
    "    {\"input_layer\" : 5 , \"output_layer\" : 1 , \"activation\" : \"sigmoid\"} ,\n",
    "]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_layer(neuralnet , seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    weights_baise = {}\n",
    "    \n",
    "    for idx , layer in enumerate(neuralnet):\n",
    "        layer_idx = idx + 1\n",
    "        input_size = layer[\"input_layer\"]\n",
    "        output_size = layer[\"output_layer\"]\n",
    "        weights_baise[\"W\" + str(layer_idx)] = np.random.randn(output_size , input_size) * 0.1\n",
    "        weights_baise[\"b\" + str(layer_idx)] = np.random.randn(output_size , 1) * 0.1\n",
    "    \n",
    "    return weights_baise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'W1': array([[ 0.04967142, -0.01382643],\n",
      "       [ 0.06476885,  0.15230299],\n",
      "       [-0.02341534, -0.0234137 ],\n",
      "       [ 0.15792128,  0.07674347],\n",
      "       [-0.04694744,  0.054256  ]])\n",
      "  'W2': array([[-0.05622875, -0.10128311,  0.03142473, -0.09080241, -0.14123037]])\n",
      "  'b1': array([[-0.04634177],\n",
      "       [-0.04657298],\n",
      "       [ 0.02419623],\n",
      "       [-0.19132802],\n",
      "       [-0.17249178]])\n",
      "  'b2': array([[0.14656488]])\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pp(first_layer(neuralnet, 42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (Z):\n",
    "    return 1 / ( 1 + np.exp( - Z))\n",
    "\n",
    "def sigmoid_backprop(dA , Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0 , Z)\n",
    "\n",
    "def relu_backprop(dA , Z):\n",
    "    dZ = np.array(dA , copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_forward_layer(A_prev , W_curr , b_curr , activation = \"relu\"):\n",
    "    Z_curr = np.dot(W_curr , A_prev ) + b_curr\n",
    "    \n",
    "    if activation is \"relu\":\n",
    "        activation_func = relu\n",
    "    elif activation is \"sigmoid\":\n",
    "        activation_func = sigmoid\n",
    "    else:\n",
    "        raise Exception(\"activation function not defined\")\n",
    "    \n",
    "    return activation_func(Z_curr) , Z_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_forward_layer(neuralnet , weights_baise , x):\n",
    "    memory = {}\n",
    "    A_curr = x\n",
    "    data = []\n",
    "    for idx , layer in enumerate(neuralnet):\n",
    "        layer_idx = idx + 1\n",
    "        A_prev = A_curr\n",
    "        activation_func = layer[\"activation\"]\n",
    "        W_curr =  weights_baise[\"W\" + str(layer_idx)] \n",
    "        b_curr =  weights_baise[\"b\" + str(layer_idx)]\n",
    "        A_curr , Z_curr = single_forward_layer(A_prev , W_curr , b_curr , activation_func)\n",
    "        \n",
    "        memory[\"A\" + str(idx)] = A_prev\n",
    "        memory[\"Z\" + str(layer_idx)] = Z_curr\n",
    "        data.append([{\"index\" : idx ,\"A_prev\" : A_prev , \"W_curr\" : W_curr ,\"b_curr\" : b_curr , \"Z_curr\" : Z_curr , \"A_curr\" : A_curr}])\n",
    "    \n",
    "    return memory , A_curr , data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_baise_ = first_layer(neuralnet , 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      'A_curr': array([[0.        , 0.        , 0.0076552 , 0.04033433],\n",
      "       [0.        , 0.        , 0.        , 0.16643839],\n",
      "       [0.04060802, 0.01646431, 0.01218105, 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.15509902],\n",
      "       [0.        , 0.        , 0.        , 0.        ]])\n",
      "      'A_prev': array([[-0.80373584,  0.04423593,  0.96210083,  1.9083946 ],\n",
      "       [ 0.10284377,  0.28599133, -0.44899971,  0.5870327 ]])\n",
      "      'W_curr': array([[ 0.04967142, -0.01382643],\n",
      "       [ 0.06476885,  0.15230299],\n",
      "       [-0.02341534, -0.0234137 ],\n",
      "       [ 0.15792128,  0.07674347],\n",
      "       [-0.04694744,  0.054256  ]])\n",
      "      'Z_curr': array([[-8.76864283e-02, -4.80987470e-02,  7.65520393e-03,\n",
      "         4.03343250e-02],\n",
      "       [-8.29666117e-02, -1.50530606e-04, -5.26428037e-02,\n",
      "         1.66438388e-01],\n",
      "       [ 4.06080205e-02,  1.64643138e-02,  1.21810541e-02,\n",
      "        -3.42340814e-02],\n",
      "       [-3.10362431e-01, -1.62394261e-01, -7.38496250e-02,\n",
      "         1.55099025e-01],\n",
      "       [-1.29178552e-01, -1.59051800e-01, -2.42020883e-01,\n",
      "        -2.30235973e-01]])\n",
      "      'b_curr': array([[-0.04634177],\n",
      "       [-0.04657298],\n",
      "       [ 0.02419623],\n",
      "       [-0.19132802],\n",
      "       [-0.17249178]])\n",
      "      'index': 0,\n",
      "    },\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      'A_curr': array([[0.53689307, 0.53670442, 0.53656392, 0.52830873]])\n",
      "      'A_prev': array([[0.        , 0.        , 0.0076552 , 0.04033433],\n",
      "       [0.        , 0.        , 0.        , 0.16643839],\n",
      "       [0.04060802, 0.01646431, 0.01218105, 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.15509902],\n",
      "       [0.        , 0.        , 0.        , 0.        ]])\n",
      "      'W_curr': array([[-0.05622875, -0.10128311,  0.03142473, -0.09080241, -0.14123037]])\n",
      "      'Z_curr': array([[0.14784097, 0.14708226, 0.14651722, 0.11335617]])\n",
      "      'b_curr': array([[0.14656488]])\n",
      "      'index': 1,\n",
      "    },\n",
      "  ],\n",
      "]\n"
     ]
    }
   ],
   "source": [
    " _ , _ , data = full_forward_layer(neuralnet , weights_baise_ , x_train.T)\n",
    "pp(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory , y_hat_train , _ =   full_forward_layer(neuralnet , weights_baise_ , x_train.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_value(y , y_hat):\n",
    "    m = y_hat.shape[1]\n",
    "    cost = - 1 / m * (np.dot(y , np.log(y_hat).T) + np.dot(1 - y , np.log(1 - y_hat).T))\n",
    "    return np.squeeze(cost)\n",
    "\n",
    "def probtoclass(prob):\n",
    "    prob_ = np.copy(prob)\n",
    "    prob_[prob_ > 0.5] = 1\n",
    "    prob_[prob_ <= 0.5] = 0\n",
    "    return prob_\n",
    "\n",
    "def accuracy_value(y , y_hat):\n",
    "    y_hat_ = probtoclass(y_hat)\n",
    "    return (y_hat_ == y).all(axis = 0).mean()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train data [0 1 1 1]\n",
      "y_train changed [[0 1 1 1]]\n",
      "A_curr / y_hat [[0.53689307 0.53670442 0.53656392 0.52830873]]\n",
      "costvalue 0.6631872730484996\n",
      "probtoclass [[1. 1. 1. 1.]]\n",
      "accuracyvalue 0.75\n"
     ]
    }
   ],
   "source": [
    "#np.transpose(y_train.reshape((y_train.shape[0] , 1)))\n",
    "\n",
    "CV = cost_value(y_train.reshape((y_train.shape[0] , 1)).T , y_hat_train )\n",
    "ptoc = probtoclass(y_hat_train)\n",
    "AV = accuracy_value(y_train.reshape((y_train.shape[0] , 1)).T , y_hat_train)\n",
    "print(\"y_train data\" ,y_train)\n",
    "print(\"y_train changed\" , y_train.reshape((y_train.shape[0] , 1)).T)\n",
    "print(\"A_curr / y_hat\" ,y_hat_train)\n",
    "print(\"costvalue\" , CV )\n",
    "print(\"probtoclass\" , ptoc)\n",
    "print(\"accuracyvalue\" , AV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_backprop(dA_curr , Z_curr , A_prev , W_curr , b_curr , activation = \"relu\"):\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    if activation is \"relu\":\n",
    "        activation_func = relu_backprop\n",
    "    elif activation is \"sigmoid\":\n",
    "        activation_func = sigmoid_backprop\n",
    "    else:\n",
    "        raise Exception(\"activation function not defined\")\n",
    "        \n",
    "    dZ_curr = activation_func(dA_curr , Z_curr)\n",
    "    dW_curr = np.dot(dZ_curr , A_prev.T) / m\n",
    "    db_curr = np.sum(dZ_curr , axis = 1 , keepdims= True ) / m\n",
    "    dA_prev = np.dot(W_curr.T , dZ_curr)\n",
    "    \n",
    "    return dA_prev , dW_curr , db_curr ,dZ_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_backprop(y , y_hat , memory , weights_baise, neuralnet ):\n",
    "    grad_value = {}\n",
    "    backprop_data = []\n",
    "    m = y.shape[1]\n",
    "    y = y.reshape(y_hat.shape)\n",
    "    \n",
    "    dA_prev = - (np.divide(y , y_hat) - np.divide(1- y , 1 - y_hat));\n",
    "    \n",
    "    for idx , layer in reversed(list(enumerate(neuralnet))):\n",
    "        layer_idx = idx + 1\n",
    "        activation_func = layer[\"activation\"]\n",
    "        \n",
    "        dA_curr = dA_prev\n",
    "        \n",
    "        A_prev = memory[\"A\" + str(idx)]\n",
    "        Z_curr = memory[\"Z\" + str(layer_idx)]\n",
    "        \n",
    "        W_curr = weights_baise[\"W\" + str(layer_idx)]\n",
    "        b_curr =  weights_baise[\"b\" + str(layer_idx)]\n",
    "        \n",
    "        dA_prev , dW_curr , db_curr , dZ_curr = single_backprop(dA_curr , Z_curr , A_prev , W_curr , b_curr , activation_func)\n",
    "        \n",
    "        grad_value[\"dW\" + str(layer_idx)] = dW_curr\n",
    "        grad_value[\"db\" + str(layer_idx)] = db_curr\n",
    "        \n",
    "        backprop_data.append([{\"idx\" : idx ,\"Y_train reshape\" : y_train.reshape((y_train.shape[0] , 1)),\"Y_hat/A_curr\" : y_hat_train, \"dA_prev/singleback\" : dA_prev , \"dA_curr/ dA_prev divid\" : dA_curr , \"Z_curr\" : Z_curr , \"dZ_curr\" : dZ_curr , \"dW_curr\" : dW_curr , \"db_curr\" : db_curr , \"m\": m}])\n",
    "    \n",
    "    return grad_value , backprop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dW2': array([[-0.00564326, -0.01962688,  0.0021323 , -0.01828971,  0.        ]]),\n",
       " 'db2': array([[-0.21538246]]),\n",
       " 'dW1': array([[ 0.01892161,  0.00096735],\n",
       "        [ 0.02279308,  0.00701128],\n",
       "        [-0.00705396,  0.00102759],\n",
       "        [ 0.02043447,  0.00628576],\n",
       "        [ 0.        ,  0.        ]]),\n",
       " 'db1': array([[ 0.01314526],\n",
       "        [ 0.01194359],\n",
       "        [-0.00306264],\n",
       "        [ 0.01070768],\n",
       "        [ 0.        ]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train.reshape((y_train.shape[0] , 1)).T , y_hat_train\n",
    "grad_value , _ = full_backprop(y_train.reshape((y_train.shape[0] , 1)) , y_hat_train , memory , weights_baise_ , neuralnet)\n",
    "grad_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      'A_curr': array([[0.        , 0.        , 0.0076552 , 0.04033433],\n",
      "       [0.        , 0.        , 0.        , 0.16643839],\n",
      "       [0.04060802, 0.01646431, 0.01218105, 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.15509902],\n",
      "       [0.        , 0.        , 0.        , 0.        ]])\n",
      "      'A_prev': array([[-0.80373584,  0.04423593,  0.96210083,  1.9083946 ],\n",
      "       [ 0.10284377,  0.28599133, -0.44899971,  0.5870327 ]])\n",
      "      'W_curr': array([[ 0.04967142, -0.01382643],\n",
      "       [ 0.06476885,  0.15230299],\n",
      "       [-0.02341534, -0.0234137 ],\n",
      "       [ 0.15792128,  0.07674347],\n",
      "       [-0.04694744,  0.054256  ]])\n",
      "      'Z_curr': array([[-8.76864283e-02, -4.80987470e-02,  7.65520393e-03,\n",
      "         4.03343250e-02],\n",
      "       [-8.29666117e-02, -1.50530606e-04, -5.26428037e-02,\n",
      "         1.66438388e-01],\n",
      "       [ 4.06080205e-02,  1.64643138e-02,  1.21810541e-02,\n",
      "        -3.42340814e-02],\n",
      "       [-3.10362431e-01, -1.62394261e-01, -7.38496250e-02,\n",
      "         1.55099025e-01],\n",
      "       [-1.29178552e-01, -1.59051800e-01, -2.42020883e-01,\n",
      "        -2.30235973e-01]])\n",
      "      'b_curr': array([[-0.04634177],\n",
      "       [-0.04657298],\n",
      "       [ 0.02419623],\n",
      "       [-0.19132802],\n",
      "       [-0.17249178]])\n",
      "      'index': 0,\n",
      "    },\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      'A_curr': array([[0.53689307, 0.53670442, 0.53656392, 0.52830873]])\n",
      "      'A_prev': array([[0.        , 0.        , 0.0076552 , 0.04033433],\n",
      "       [0.        , 0.        , 0.        , 0.16643839],\n",
      "       [0.04060802, 0.01646431, 0.01218105, 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.15509902],\n",
      "       [0.        , 0.        , 0.        , 0.        ]])\n",
      "      'W_curr': array([[-0.05622875, -0.10128311,  0.03142473, -0.09080241, -0.14123037]])\n",
      "      'Z_curr': array([[0.14784097, 0.14708226, 0.14651722, 0.11335617]])\n",
      "      'b_curr': array([[0.14656488]])\n",
      "      'index': 1,\n",
      "    },\n",
      "  ],\n",
      "]\n",
      "[\n",
      "  [\n",
      "    {\n",
      "      'Y_hat/A_curr': array([[0.53689307, 0.53670442, 0.53656392, 0.52830873]])\n",
      "      'Y_train reshape': array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]], dtype=int64)\n",
      "      'Z_curr': array([[0.14784097, 0.14708226, 0.14651722, 0.11335617]])\n",
      "      'dA_curr/ dA_prev divid': array([[ 2.15932852, -1.86322296, -1.86371086, -1.89283261]])\n",
      "      'dA_prev/singleback': array([[-0.03018883,  0.02605053,  0.02605843,  0.02652261],\n",
      "       [-0.0543782 ,  0.04692402,  0.04693825,  0.04777436],\n",
      "       [ 0.01687172, -0.01455894, -0.01456336, -0.01482277],\n",
      "       [-0.04875118,  0.04206835,  0.04208111,  0.0428307 ],\n",
      "       [-0.07582561,  0.06543141,  0.06545125,  0.06661713]])\n",
      "      'dW_curr': array([[-0.00564326, -0.01962688,  0.0021323 , -0.01828971,  0.        ]])\n",
      "      'dZ_curr': array([[ 0.53689307, -0.46329558, -0.46343608, -0.47169127]])\n",
      "      'db_curr': array([[-0.21538246]])\n",
      "      'idx': 1,\n",
      "      'm': 1,\n",
      "    },\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      'Y_hat/A_curr': array([[0.53689307, 0.53670442, 0.53656392, 0.52830873]])\n",
      "      'Y_train reshape': array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]], dtype=int64)\n",
      "      'Z_curr': array([[-8.76864283e-02, -4.80987470e-02,  7.65520393e-03,\n",
      "         4.03343250e-02],\n",
      "       [-8.29666117e-02, -1.50530606e-04, -5.26428037e-02,\n",
      "         1.66438388e-01],\n",
      "       [ 4.06080205e-02,  1.64643138e-02,  1.21810541e-02,\n",
      "        -3.42340814e-02],\n",
      "       [-3.10362431e-01, -1.62394261e-01, -7.38496250e-02,\n",
      "         1.55099025e-01],\n",
      "       [-1.29178552e-01, -1.59051800e-01, -2.42020883e-01,\n",
      "        -2.30235973e-01]])\n",
      "      'dA_curr/ dA_prev divid': array([[-0.03018883,  0.02605053,  0.02605843,  0.02652261],\n",
      "       [-0.0543782 ,  0.04692402,  0.04693825,  0.04777436],\n",
      "       [ 0.01687172, -0.01455894, -0.01456336, -0.01482277],\n",
      "       [-0.04875118,  0.04206835,  0.04208111,  0.0428307 ],\n",
      "       [-0.07582561,  0.06543141,  0.06545125,  0.06661713]])\n",
      "      'dA_prev/singleback': array([[-3.95057053e-04,  3.40902494e-04,  1.63536512e-03,\n",
      "         1.11755856e-02],\n",
      "       [-3.95029354e-04,  3.40878591e-04, -1.93131338e-05,\n",
      "         1.01964414e-02]])\n",
      "      'dW_curr': array([[ 0.01892161,  0.00096735],\n",
      "       [ 0.02279308,  0.00701128],\n",
      "       [-0.00705396,  0.00102759],\n",
      "       [ 0.02043447,  0.00628576],\n",
      "       [ 0.        ,  0.        ]])\n",
      "      'dZ_curr': array([[ 0.        ,  0.        ,  0.02605843,  0.02652261],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.04777436],\n",
      "       [ 0.01687172, -0.01455894, -0.01456336,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.0428307 ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ]])\n",
      "      'db_curr': array([[ 0.01314526],\n",
      "       [ 0.01194359],\n",
      "       [-0.00306264],\n",
      "       [ 0.01070768],\n",
      "       [ 0.        ]])\n",
      "      'idx': 0,\n",
      "      'm': 1,\n",
      "    },\n",
      "  ],\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "_ , backprop_data = full_backprop(y_train.reshape((y_train.shape[0] , 1)) , y_hat_train , memory , weights_baise_ , neuralnet)\n",
    "\n",
    "pp(data)\n",
    "pp(backprop_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breakdown of parts in last layer as first layer back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting the value of dZ_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05622875, -0.10128311,  0.03142473, -0.09080241, -0.14123037]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((list(data)[1])[0])[\"W_curr\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_prev1 [[0.         0.         0.0076552  0.04033433]\n",
      " [0.         0.         0.         0.16643839]\n",
      " [0.04060802 0.01646431 0.01218105 0.        ]\n",
      " [0.         0.         0.         0.15509902]\n",
      " [0.         0.         0.         0.        ]]\n",
      "W_curr1 [[-0.05622875 -0.10128311  0.03142473 -0.09080241 -0.14123037]]\n",
      "Z_curr1 [[0.14784097 0.14708226 0.14651722 0.11335617]]\n"
     ]
    }
   ],
   "source": [
    "A_prev1 = np.array(((list(data)[1])[0])[\"A_prev\"])\n",
    "W_curr1 = np.array(((list(data)[1])[0])[\"W_curr\"])\n",
    "\n",
    "\n",
    "Z_curr1 = np.array(((list(data)[1])[0])[\"Z_curr\"])\n",
    "#m = y_train.reshape((y_train.shape[0] , 1)).shape[1]\n",
    "m = A_prev1.shape[1]\n",
    "print(\"A_prev1\" , A_prev1)\n",
    "print(\"W_curr1\" , W_curr1)\n",
    "print(\"Z_curr1\" , Z_curr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = np.transpose(y_train.reshape((y_train.shape[0] , 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev_To_dA_curr_ [[ 2.15932852 -1.86322296 -1.86371086 -1.89283261]]\n",
      "Value of Y [[0 1 1 1]]\n",
      "Y_hat [[0.53689307 0.53670442 0.53656392 0.52830873]]\n"
     ]
    }
   ],
   "source": [
    "dA_prev_To_dA_curr_ = -( np.divide(y_train_.reshape(y_hat_train.shape) , y_hat_train) - np.divide(1 - y_train_.reshape(y_hat_train.shape) ,1 - y_hat_train))\n",
    "\n",
    "print(\"dA_prev_To_dA_curr_\" ,dA_prev_To_dA_curr_)\n",
    "print(\"Value of Y\",np.transpose(y_train.reshape((y_train.shape[0] , 1))).reshape(y_hat_train.shape))\n",
    "print(\"Y_hat\",y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53689307, -0.46329558, -0.46343608, -0.47169127]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ_curr1 = sigmoid_backprop(dA_prev_To_dA_curr_ , Z_curr1)\n",
    "dZ_curr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking value of dW_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW_curr [[-0.00564326 -0.01962688  0.0021323  -0.01828971  0.        ]]\n",
      "db_curr [[-0.21538246]]\n"
     ]
    }
   ],
   "source": [
    "dW_curr1 = np.dot(dZ_curr1 , A_prev1.T)  /  m # this part is m\n",
    "db_curr1 = np.sum(dZ_curr1 , axis = 1 , keepdims = True) / m\n",
    "\n",
    "print(\"dW_curr\" , dW_curr1)\n",
    "print(\"db_curr\" , db_curr1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### checking value of dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03018883,  0.02605053,  0.02605843,  0.02652261],\n",
       "       [-0.0543782 ,  0.04692402,  0.04693825,  0.04777436],\n",
       "       [ 0.01687172, -0.01455894, -0.01456336, -0.01482277],\n",
       "       [-0.04875118,  0.04206835,  0.04208111,  0.0428307 ],\n",
       "       [-0.07582561,  0.06543141,  0.06545125,  0.06661713]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dA_prev = np.dot(W_curr.T , dZ_curr)\n",
    "dA_prev1 = np.dot(np.transpose(W_curr1 ), dZ_curr1) \n",
    "dA_prev1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breakdown of parts in second layer back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.76864283e-02, -4.80987470e-02,  7.65520393e-03,\n",
       "         4.03343250e-02],\n",
       "       [-8.29666117e-02, -1.50530606e-04, -5.26428037e-02,\n",
       "         1.66438388e-01],\n",
       "       [ 4.06080205e-02,  1.64643138e-02,  1.21810541e-02,\n",
       "        -3.42340814e-02],\n",
       "       [-3.10362431e-01, -1.62394261e-01, -7.38496250e-02,\n",
       "         1.55099025e-01],\n",
       "       [-1.29178552e-01, -1.59051800e-01, -2.42020883e-01,\n",
       "        -2.30235973e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((list(data)[0])[0])[\"Z_curr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_prev0 [[-0.80373584  0.04423593  0.96210083  1.9083946 ]\n",
      " [ 0.10284377  0.28599133 -0.44899971  0.5870327 ]]\n",
      "W_curr0 [[ 0.04967142 -0.01382643]\n",
      " [ 0.06476885  0.15230299]\n",
      " [-0.02341534 -0.0234137 ]\n",
      " [ 0.15792128  0.07674347]\n",
      " [-0.04694744  0.054256  ]]\n",
      "Z_curr0 [[-8.76864283e-02 -4.80987470e-02  7.65520393e-03  4.03343250e-02]\n",
      " [-8.29666117e-02 -1.50530606e-04 -5.26428037e-02  1.66438388e-01]\n",
      " [ 4.06080205e-02  1.64643138e-02  1.21810541e-02 -3.42340814e-02]\n",
      " [-3.10362431e-01 -1.62394261e-01 -7.38496250e-02  1.55099025e-01]\n",
      " [-1.29178552e-01 -1.59051800e-01 -2.42020883e-01 -2.30235973e-01]]\n"
     ]
    }
   ],
   "source": [
    "A_prev0 = np.array(((list(data)[0])[0])[\"A_prev\"])\n",
    "\n",
    "W_curr0 = np.array(((list(data)[0])[0])[\"W_curr\"])\n",
    "\n",
    "\n",
    "Z_curr0 = np.array(((list(data)[0])[0])[\"Z_curr\"])\n",
    "\n",
    "#m = y_train.reshape((y_train.shape[0] , 1)).shape[1]\n",
    "m = A_prev1.shape[1]\n",
    "\n",
    "print(\"A_prev0\" , A_prev0)\n",
    "print(\"W_curr0\" , W_curr0)\n",
    "print(\"Z_curr0\" , Z_curr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev_To_dA_curr_ [[-0.03018883  0.02605053  0.02605843  0.02652261]\n",
      " [-0.0543782   0.04692402  0.04693825  0.04777436]\n",
      " [ 0.01687172 -0.01455894 -0.01456336 -0.01482277]\n",
      " [-0.04875118  0.04206835  0.04208111  0.0428307 ]\n",
      " [-0.07582561  0.06543141  0.06545125  0.06661713]]\n",
      "Value of Y [[0 1 1 1]]\n",
      "Y_hat [[0.53689307 0.53670442 0.53656392 0.52830873]]\n"
     ]
    }
   ],
   "source": [
    "dA_prev_To_dA_curr_0 = dA_prev1\n",
    "\n",
    "print(\"dA_prev_To_dA_curr_\" ,dA_prev_To_dA_curr_0)\n",
    "\n",
    "print(\"Value of Y\",np.transpose(y_train.reshape((y_train.shape[0] , 1))).reshape(y_hat_train.shape))\n",
    "\n",
    "print(\"Y_hat\",y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.02605843,  0.02652261],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.04777436],\n",
       "       [ 0.01687172, -0.01455894, -0.01456336,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.0428307 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ_curr0 = relu_backprop(dA_prev_To_dA_curr_0 , Z_curr0)\n",
    "dZ_curr0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking value of dW_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW_curr [[ 0.01892161  0.00096735]\n",
      " [ 0.02279308  0.00701128]\n",
      " [-0.00705396  0.00102759]\n",
      " [ 0.02043447  0.00628576]\n",
      " [ 0.          0.        ]]\n",
      "db_curr [[ 0.01314526]\n",
      " [ 0.01194359]\n",
      " [-0.00306264]\n",
      " [ 0.01070768]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "dW_curr0 = np.dot(dZ_curr0 , A_prev0.T)  /  m # this part is m\n",
    "db_curr0 = np.sum(dZ_curr0 , axis = 1 , keepdims = True) / m\n",
    "\n",
    "print(\"dW_curr\" , dW_curr0)\n",
    "print(\"db_curr\" , db_curr0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking value of dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.95057053e-04,  3.40902494e-04,  1.63536512e-03,\n",
       "         1.11755856e-02],\n",
       "       [-3.95029354e-04,  3.40878591e-04, -1.93131338e-05,\n",
       "         1.01964414e-02]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA_prev0 = np.dot(np.transpose(W_curr0 ), dZ_curr0) \n",
    "dA_prev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_curr0 = np.array(((list(data)[0])[0])[\"b_curr\"])\n",
    "b_curr1 = np.array(((list(data)[1])[0])[\"b_curr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(neuralnet, learning_rate , grad_value , weights_baise):\n",
    "    \n",
    "    for layer_idx , layer in enumerate(neuralnet , 1):\n",
    "    \n",
    "        weights_baise[\"W\" + str(layer_idx)] -= learning_rate *  grad_value[\"dW\" + str(layer_idx)]\n",
    "        weights_baise[\"b\" + str(layer_idx)] -= learning_rate *  grad_value[\"db\" + str(layer_idx)]\n",
    "    \n",
    "    return weights_baise\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  running the below code of \"update\" changes the values of weights andd baise so when \"train\" function is used it gives different values of weights and baise. it changes the previous values of W_curr and b_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'W1': array([[ 0.0494822 , -0.0138361 ],\n",
      "       [ 0.06454092,  0.15223287],\n",
      "       [-0.0233448 , -0.02342397],\n",
      "       [ 0.15771694,  0.07668062],\n",
      "       [-0.04694744,  0.054256  ]])\n",
      "  'W2': array([[-0.05617232, -0.10108684,  0.03140341, -0.09061951, -0.14123037]])\n",
      "  'b1': array([[-0.04647322],\n",
      "       [-0.04669241],\n",
      "       [ 0.02422685],\n",
      "       [-0.1914351 ],\n",
      "       [-0.17249178]])\n",
      "  'b2': array([[0.1487187]])\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "weights_baise__ = update(neuralnet , 0.01 , grad_value , weights_baise_)\n",
    "pp(weights_baise__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01892161  0.00096735]\n",
      " [ 0.02279308  0.00701128]\n",
      " [-0.00705396  0.00102759]\n",
      " [ 0.02043447  0.00628576]\n",
      " [ 0.          0.        ]]\n",
      "[[ 0.04967142 -0.01382643]\n",
      " [ 0.06476885  0.15230299]\n",
      " [-0.02341534 -0.0234137 ]\n",
      " [ 0.15792128  0.07674347]\n",
      " [-0.04694744  0.054256  ]]\n",
      "[[-0.00564326 -0.01962688  0.0021323  -0.01828971  0.        ]]\n",
      "[[-0.05622875 -0.10128311  0.03142473 -0.09080241 -0.14123037]]\n"
     ]
    }
   ],
   "source": [
    "#((list(data)[0])[0])\n",
    "print(dW_curr0)\n",
    "print(W_curr0)\n",
    "print(dW_curr1)\n",
    "print(W_curr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightupdate1 [[ 0.0494822  -0.0138361 ]\n",
      " [ 0.06454092  0.15223287]\n",
      " [-0.0233448  -0.02342397]\n",
      " [ 0.15771694  0.07668062]\n",
      " [-0.04694744  0.054256  ]]\n",
      "weightupdate2 [[-0.05617232 -0.10108684  0.03140341 -0.09061951 -0.14123037]]\n",
      "baiseupadte1 [[-0.04647322]\n",
      " [-0.04669241]\n",
      " [ 0.02422685]\n",
      " [-0.1914351 ]\n",
      " [-0.17249178]]\n",
      "baiseupdate2 [[0.1487187]]\n"
     ]
    }
   ],
   "source": [
    "weightupdate1 = W_curr0 - 0.01 * dW_curr0\n",
    "weightupdate2 = W_curr1 - 0.01 * dW_curr1\n",
    "baiseupadte1 =  b_curr0 - 0.01 * db_curr0\n",
    "baiseupdate2 =  b_curr1 - 0.01 * db_curr1\n",
    "\n",
    "print(\"weightupdate1\" , weightupdate1)\n",
    "print(\"weightupdate2\" , weightupdate2)\n",
    "print(\"baiseupadte1\" , baiseupadte1)\n",
    "print(\"baiseupdate2\" , baiseupdate2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x , y , learning_rate  , epoch , neuralnet , callback = None , lossfunction = False ):\n",
    "    cost_value_history = []\n",
    "    accuracy_value_history = []\n",
    "    \n",
    "    back_prop_history = []\n",
    "    lossfunc = []\n",
    "    updatedweight_baise = []\n",
    "    weights_baise = first_layer(neuralnet , 42)\n",
    "    forward_prop_history = []\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        \n",
    "       \n",
    "    \n",
    "        memory , y_hat , data = full_forward_layer(neuralnet , weights_baise , x)\n",
    "        \n",
    "        forward_prop_history.append([i , data])\n",
    "        \n",
    "        cost = cost_value(y , y_hat)\n",
    "        cost_value_history.append(cost)\n",
    "        accuracy = accuracy_value(y , y_hat)\n",
    "        accuracy_value_history.append(accuracy)\n",
    "        \n",
    "    \n",
    "        grad_value , backprop_data = full_backprop(y , y_hat , memory , weights_baise, neuralnet )\n",
    "        \n",
    "        back_prop_history.append([i , backprop_data])\n",
    "    \n",
    "        weights_baise = update(neuralnet, learning_rate , grad_value , weights_baise)\n",
    "        \n",
    "        updatedweight_baise.append([{\"loop\" : i , \"weightsafterlearning\" : weights_baise}])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if (i % 100 == 0):\n",
    "        \n",
    "            if(lossfunction is not None):\n",
    "                lossfunc.append([i , cost , accuracy])\n",
    "            if(callback is not None):\n",
    "                callback(i , weights_baise)\n",
    "    \n",
    "    \n",
    "    return weights_baise , lossfunc , forward_prop_history , back_prop_history , updatedweight_baise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_baise , lossfunc , forward_prop_history , back_prop_history , updatedweight_baise = train(x_train.T , y_train_ , 0.01  , 1 , neuralnet , callback = None , lossfunction = None )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using weights and baise with Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53622688]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, Y_test_hat , _ = full_forward_layer(neuralnet  , weights_baise , np.transpose(x_test))\n",
    "Y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy achieved on the test set\n",
    "acc_test = accuracy_value( np.transpose(y_test.reshape((y_test.shape[0], 1))) , Y_test_hat )\n",
    "print((acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_prop_history [0, [[{'index': 0, 'A_prev': array([[-0.80373584,  0.04423593,  0.96210083,  1.9083946 ],\n",
      "       [ 0.10284377,  0.28599133, -0.44899971,  0.5870327 ]]), 'W_curr': array([[ 0.0494822 , -0.0138361 ],\n",
      "       [ 0.06454092,  0.15223287],\n",
      "       [-0.0233448 , -0.02342397],\n",
      "       [ 0.15771694,  0.07668062],\n",
      "       [-0.04694744,  0.054256  ]]), 'b_curr': array([[-0.04647322],\n",
      "       [-0.04669241],\n",
      "       [ 0.02422685],\n",
      "       [-0.1914351 ],\n",
      "       [-0.17249178]]), 'Z_curr': array([[-8.76864283e-02, -4.80987470e-02,  7.65520393e-03,\n",
      "         4.03343250e-02],\n",
      "       [-8.29666117e-02, -1.50530606e-04, -5.26428037e-02,\n",
      "         1.66438388e-01],\n",
      "       [ 4.06080205e-02,  1.64643138e-02,  1.21810541e-02,\n",
      "        -3.42340814e-02],\n",
      "       [-3.10362431e-01, -1.62394261e-01, -7.38496250e-02,\n",
      "         1.55099025e-01],\n",
      "       [-1.29178552e-01, -1.59051800e-01, -2.42020883e-01,\n",
      "        -2.30235973e-01]]), 'A_curr': array([[0.        , 0.        , 0.0076552 , 0.04033433],\n",
      "       [0.        , 0.        , 0.        , 0.16643839],\n",
      "       [0.04060802, 0.01646431, 0.01218105, 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.15509902],\n",
      "       [0.        , 0.        , 0.        , 0.        ]])}], [{'index': 1, 'A_prev': array([[0.        , 0.        , 0.0076552 , 0.04033433],\n",
      "       [0.        , 0.        , 0.        , 0.16643839],\n",
      "       [0.04060802, 0.01646431, 0.01218105, 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.15509902],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), 'W_curr': array([[-0.05617232, -0.10108684,  0.03140341, -0.09061951, -0.14123037]]), 'b_curr': array([[0.1487187]]), 'Z_curr': array([[0.14784097, 0.14708226, 0.14651722, 0.11335617]]), 'A_curr': array([[0.53689307, 0.53670442, 0.53656392, 0.52830873]])}]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"forward_prop_history\" , forward_prop_history[0])\n",
    "#pp(updatedweight_baise)\n",
    "#pp(forward_prop_history[0])\n",
    "\n",
    "#print(\"back_prop_history\" , back_prop_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      'loop': 0,\n",
      "      'weightsafterlearning': {\n",
      "        'W1': array([[ 0.0494822 , -0.0138361 ],\n",
      "       [ 0.06454092,  0.15223287],\n",
      "       [-0.0233448 , -0.02342397],\n",
      "       [ 0.15771694,  0.07668062],\n",
      "       [-0.04694744,  0.054256  ]])\n",
      "        'W2': array([[-0.05617232, -0.10108684,  0.03140341, -0.09061951, -0.14123037]])\n",
      "        'b1': array([[-0.04647322],\n",
      "       [-0.04669241],\n",
      "       [ 0.02422685],\n",
      "       [-0.1914351 ],\n",
      "       [-0.17249178]])\n",
      "        'b2': array([[0.1487187]])\n",
      "      },\n",
      "    },\n",
      "  ],\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "pp(updatedweight_baise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lossfun = np.array(lossfunc , copy = True )[:,0:2]\n",
    "#lossfun.shape\n",
    "lossfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph of loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#loss_function__ = plt.plot(lossfun[:,0] , lossfun [:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_plot(X , Y, file_name=None, XX=None, YY=None, preds=None):\n",
    "\n",
    "#     if(XX is not None and YY is not None and preds is not None):\n",
    "#         plt.contourf(XX, YY, preds.reshape(XX.shape))\n",
    "#         plt.contour(XX, YY, preds.reshape(XX.shape))\n",
    "#     plt.scatter(X[:, 0], X[:, 1])\n",
    "#     if(file_name):\n",
    "#         plt.savefig(file_name)\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using numpy.mgrid to plot the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location = \"E:\\\\python folder\\\\images\\\\\"\n",
    "# grid = np.mgrid[-1.5:2.5:100j,-1.5:2:100j]\n",
    "# grid_2d = grid.reshape(2, -1).T\n",
    "# XX, YY = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def callbacks(index , weights_baise):\n",
    "#     file_name = str(index//100)\n",
    "#     file_path = os.path.join(location, file_name)\n",
    "    \n",
    "#     _ , prediction = full_forward_layer(neuralnet , weights_baise, np.transpose(grid_2d))\n",
    "#     prediction = prediction.reshape(prediction.shape[1], 1)\n",
    "#     make_plot(x_test,y_test , file_name=file_path, XX=XX, YY=YY, preds=prediction)\n",
    "    \n",
    "# def lossfunction(index , cost , accuracy):\n",
    "    \n",
    "#     return index , cost , accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     _ , prediction_ , _ = full_forward_layer(neuralnet , weights_baise, np.transpose(grid_2d))\n",
    "#     prediction_ = prediction_.reshape(prediction_.shape[1], 1)\n",
    "#     make_plot(x_test,y_test , file_name=None, XX=XX, YY=YY, preds=prediction_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
